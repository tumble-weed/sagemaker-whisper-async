{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9ec9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.local import LocalSession\n",
    "from argparse import Namespace\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199e15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8332944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating yrx2y4t3mn-algo-1-7mnu2 ... \n",
      "Creating yrx2y4t3mn-algo-1-7mnu2 ... done\n",
      "Attaching to yrx2y4t3mn-algo-1-7mnu2\n",
      "\u001b[36myrx2y4t3mn-algo-1-7mnu2 |\u001b[0m \n",
      "\u001b[36myrx2y4t3mn-algo-1-7mnu2 |\u001b[0m Starting the training.\n",
      "\u001b[36myrx2y4t3mn-algo-1-7mnu2 |\u001b[0m Training complete.\n",
      "\u001b[36myrx2y4t3mn-algo-1-7mnu2 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "args = Namespace()\n",
    "args.train_instance_type = 'ml.m4.xlarge'\n",
    "args.model_prefix = \"dummy-whisper-async\"\n",
    "sess = LocalSession()\n",
    "# sess = boto3.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sess.config = {'local': {'local_code': True}}\n",
    "# model = SKLearnModel(\n",
    "#     entry_point='inference.py',\n",
    "#     role=role,\n",
    "#     model_data=model_artifacts,\n",
    "#     framework_version='0.23-1',\n",
    "# )\n",
    "\n",
    "dummy_whisper = sagemaker.estimator.Estimator(\n",
    "                                        'dummy-whisper-async',\n",
    "                                        entry_point='serve',\n",
    "                                        role=role,\n",
    "                                        train_instance_count=1, \n",
    "                                        train_instance_type=args.train_instance_type,\n",
    "    #                                     output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    #                                       output_path='s3://sagemaker-ap-northeast-1-268945887964', \n",
    "    #                                       output_path='s3://sagemaker-ap-northeast-1-268945887964/custom_inference/',\n",
    "                                          output_path=f's3://sagemaker-ap-northeast-1-268945887964/{args.model_prefix}',# this is for saving training results\n",
    "                                        base_job_name=args.model_prefix,\n",
    "                                        sagemaker_session=sess)\n",
    "dummy_whisper.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "079d79f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1780e-02, 0.0000e+00, 4.0500e+00, 0.0000e+00, 5.1000e-01,\n",
       "        6.4160e+00, 8.4100e+01, 2.6463e+00, 5.0000e+00, 2.9600e+02,\n",
       "        1.6600e+01, 3.9550e+02, 9.0400e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "payload = np.array([[0.09178, 0.0, 4.05, 0.0, 0.51, 6.416, 84.1, 2.6463, 5.0, 296.0, 16.6, 395.5, 9.04]])\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af3696b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_endpoint_config() got an unexpected keyword argument 'AsyncInferenceConfig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24343/3992003120.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m      \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"s3://sagemaker-ap-northeast-1-268945887964/{args.model_prefix}/response\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m      max_concurrent_invocations_per_instance=1)\n\u001b[0;32m----> 9\u001b[0;31m     predictor = dummy_whisper.deploy(initial_instance_count=1, \n\u001b[0m\u001b[1;32m     10\u001b[0m                                      \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'local'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                      \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, use_compiled_model, wait, model_name, kms_key, data_capture_config, tags, serverless_inference_config, async_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         )\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m         return model.deploy(\n\u001b[0m\u001b[1;32m   1433\u001b[0m             \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0masync_inference_config_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masync_inference_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_request_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         self.sagemaker_session.endpoint_from_production_variants(\n\u001b[0m\u001b[1;32m   1197\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0mproduction_variants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict)\u001b[0m\n\u001b[1;32m   3679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3680\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating endpoint-config with name %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3681\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: create_endpoint_config() got an unexpected keyword argument 'AsyncInferenceConfig'"
     ]
    }
   ],
   "source": [
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "# try:\n",
    "if True:\n",
    "#     predictor = dummy_whisper.deploy(initial_instance_count=1, instance_type='local')\n",
    "    endpoint_name = f'{args.model_prefix}-endpoint'\n",
    "    async_config = AsyncInferenceConfig(\n",
    "     output_path = f\"s3://sagemaker-ap-northeast-1-268945887964/{args.model_prefix}/response\",\n",
    "     max_concurrent_invocations_per_instance=1)\n",
    "    predictor = dummy_whisper.deploy(initial_instance_count=1, \n",
    "                                     instance_type='local', \n",
    "                                     endpoint_name=endpoint_name,\n",
    "#                                      async_inference_config1 = 2,\n",
    "#                                      async_inference_config = 1,\n",
    "                                     async_inference_config = async_config,\n",
    "                        )\n",
    "#     print(predictor)\n",
    "#     preds = predictor.predict(payload)\n",
    "#     print(preds)\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d8f6f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m(3681)\u001b[0;36mendpoint_from_production_variants\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   3679 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3680 \u001b[0;31m        \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating endpoint-config with name %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 3681 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3682 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3683 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  config_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointConfigName': 'dummy-whisper-async-endpoint', 'ProductionVariants': [{'ModelName': 'dummy-whisper-async-2022-12-06-07-15-28-516', 'VariantName': 'AllTraffic', 'InitialVariantWeight': 1, 'InitialInstanceCount': 1, 'InstanceType': 'local'}], 'AsyncInferenceConfig': {'OutputConfig': {'S3OutputPath': 's3://sagemaker-ap-northeast-1-268945887964/dummy-whisper-async/response'}, 'ClientConfig': {'MaxConcurrentInvocationsPerInstance': 1}}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.sagemaker_client.create_endpoint_config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method LocalSagemakerClient.create_endpoint_config of <sagemaker.local.local_session.LocalSagemakerClient object at 0x7fd2f42331c0>>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a523e892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using /home/ec2-user/SageMaker/thecantervilleghostversion2_01_wilde_128kb.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "*   Trying 127.0.0.1:5000...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 127.0.0.1 (127.0.0.1) port 5000 (#0)\n",
      "> POST /invocations HTTP/1.1\n",
      "> Host: 127.0.0.1:5000\n",
      "> User-Agent: curl/7.80.0\n",
      "> Accept: */*\n",
      "> Content-Type: application/json\n",
      "> Content-Length: 14196270\n",
      "> Expect: 100-continue\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 100 Continue\n",
      "} [65536 bytes data]\n",
      "* We are completely uploaded and fine\n",
      "100 13.5M    0     0  100 13.5M      0   123k  0:01:52  0:01:52 --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\":\" CHAPTER I. When Mr. Hiram B. Otis, the American minister, bought Canterville Chase, everyone told him he was doing a very foolish thing, as there was no doubt at all that the place was haunted. Indeed, Lord Canterville himself, who was a man of the most punctilious honor, had felt it his duty to mention the fact to Mr. Otis when they came to discuss terms. \\\"'We have not cared to live in the place ourselves,' said Lord Canterville, \\\"'since my grandaunt, the dowager-duchess of Bolton, was frightened into a fit from which she never really recovered, by two skeleton hands being placed on her shoulders as she was dressing for dinner. And I feel bound to tell you, Mr. Otis, that the ghost has been seen by several living members of my family, as well as by the rector of the parish, the Reverend Augustus Dampier, who is a fellow of King's College, Cambridge. After the unfortunate accident to the duchess, none of our younger servants would stay with us, and Lady Canterville often got very little sleep at night in consequence of the mysterious noises that came from the corridor and the library. \\\"'My lord,' answered the minister, \\\"'I will take the furniture and the ghost at a valuation. I have come from a modern country where we have everything that money can buy, and with all our spry young fellows painting the old world red, and carrying off your best actors and prima donnas, I reckon that if there were such a thing as a ghost in Europe we'd have it at home in a very short time in one of our public museums, or on the road as a show.' \\\"'I fear that the ghost exists,' said Lord Canterville, smiling. \\\"'Though it may have resisted the overtures of your enterprising impresarios. It has been well known for three centuries, since 1584, in fact, and always makes its appearance before the death of any member of our family.' \\\"'Well, so does the family doctor for that matter, Lord Canterville. But there is no such thing, sir, as a ghost, and I guess the laws of nature are not going to be suspended for the British aristocracy.' \\\"'You are certainly very natural in America,' answered Lord Canterville, who did not quite understand Mr. Otis's last observation. \\\"'And if you don't mind a ghost in the house, it is all right. Only you must remember, I warned you.' A few weeks after this the purchase was concluded, and at the close of the season the minister and his family went down to Canterville Chase. Mrs. Otis, who, as Miss Lucretia, or Tappan, of West 53rd Street, had been a celebrated New York belle, was now a very handsome middle-aged woman, with fine eyes and a superb profile. Many American ladies, on leaving their native land, adopt an appearance of chronic ill-health, under the impression that it is a form of European refinement, but Mrs. Otis had never fallen into this error. She had a magnificent constitution and a really wonderful amount of animal spirits. Indeed, in many respects she was quite English, and was an excellent example of the fact that we have really everything in common with America nowadays, except, of course, language. Her eldest son christened Washington by his parents in a moment of patriotism, which she never ceased to regret, was a fair-haired, rather good-looking young man who had qualified himself for American diplomacy by leading the German at the Newport Casino for three successive seasons, and even in London was well known as an excellent dancer. Gordinha's and the peerage were his only weaknesses. Otherwise, he was extremely sensible. Miss Virginia E. Otis was a little girl of fifteen, lithe and lovely as a fawn, and with a fine freedom in her large blue eyes. She was a wonderful Amazon, and had once raced old Lord Bilton on her pony twice round the park, winning by a length and a half, just in front of the Achilles statue, to the huge delight of the young Duke of Cheshire, who proposed for her on the spot, and was sent back to Eaton that very night by his guardians in floods of tears. After Virginia came the twins, who were usually called the Stars and Stripes, as they were always getting swished. They were delightful boys, and, with the exception of the worthy minister, the only true Republicans of the family. As Canterville Chase is seven miles from Ascot, the nearest railway station, Mr. Otis had telegraphed for a wagonette to meet them, and they started on their drive in high spirits. It was a lovely July evening, and the air was delicate with the scent of the pine-woods. Now and then they heard a wood-pigeon brooding over its own sweet voice, or saw deep in the rustling fern the burnished breast of the pheasant. Little squirrels peered at them from the beech trees as they went by, and the rabbits scutted away through the brushwood and over the mossy knolls, with their white tails in the air. As they entered the avenue of Canterville Chase, however, the sky became suddenly overcast with clouds. A curious stillness seemed to hold the atmosphere. A great flight of rooks passed silently over their heads, and before they reached the house some big drops of rain had fallen. Standing on the steps to receive them was an old woman, neatly dressed in black silk with a white cap and apron. This was Mrs. Umney, the housekeeper, whom Mrs. Otis, at Lady Canterville's earnest request, had consented to keep in her former position. She made them each a low curtsy as they alighted, and said in a quaint old-fashioned manner, I bid you welcome to Canterville Chase. Following her they passed through the fine Tudor Hall into the library, a long low room panelled in black oak, at the end of which was a large stained-glass window. Here they found tea laid out for them, and after taking off their wraps they sat down and began to look round while Mrs. Umney waited on them. Suddenly Mrs. Otis caught sight of a dull red stain on the floor just by the fireplace, and quite unconscious of what it really signified, said to Mrs. Umney, I am afraid something has been spilt there. Yes, madam, replied the old housekeeper in a low voice, blood has been spilt on that spot. How horrid! cried Mrs. Otis. I don't care at all for bloodstains in a sitting-room, it must be removed at once. The old woman smiled, and answered in the same low mysterious voice, It is the blood of Lady Eleanor de Canterville, who was murdered on that very spot by her own husband, Sir Simon de Canterville, in 1575. Sir Simon survived her nine years, and disappeared suddenly under very mysterious circumstances. His body has never been discovered, but his guilty spirit still haunts the chase. The bloodstain has been much admired by tourists and others, and cannot be removed. This is all nonsense, cried Washington Otis. Washington's champion stain-remover and paragon detergent will clean it up in no time. And before the terrified housekeeper could interfere, he had fallen upon his knees, and was rapidly scouring the floor with a small stick of what looked like a black cosmetic. In a few moments no trace of the bloodstain could be seen. \\\"'I knew Pinkerton would do it,' he exclaimed triumphantly, as he looked round at his admiring family. But no sooner had he said these words than a terrible flash of lightning lit up the somber room, a fearful peal of thunder made them all start to their feet, and Miseress Omni fainted. \\\"'What a monstrous climate!' said the American minister calmly, as he lit a long charute. \\\"'I guess the old country is so overpopulated that they have not enough decent weather for everybody. I have always been of the opinion that immigration is the only thing for England.' \\\"'My dear Hiram,' cried Mrs. Otis, \\\"'what can we do with a woman who faints?' \\\"'Charge it to her like breakages,' answered the minister. She won't faint after that.\\\" And in a few moments Miseress Omni certainly came to. There was no doubt, however, that she was extremely upset, and she sternly warned Mr. Otis to beware of some trouble coming to the house. \\\"'I have seen things with my own eyes, sir,' she said, \\\"'that would make any Christian's hair stand on end. And many, and many a night I have not closed my eyes in sleep for the awful things that are done here.' Mr. Otis, however, and his wife warmly assured the honest soul that they were not afraid of ghosts, and, after invoking the blessings of Providence on her new master and mistress, and making arrangements for an increase of salary, the old housekeeper tottered off to her own room.\"}\n",
      "CPU times: user 178 ms, sys: 76.8 ms, total: 254 ms\n",
      "Wall time: 1min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100 13.5M    0     0  100 13.5M      0   122k  0:01:53  0:01:53 --:--:--     0* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\r\n",
      "< Server: nginx/1.14.0 (Ubuntu)\r\n",
      "< Date: Tue, 06 Dec 2022 15:31:04 GMT\r\n",
      "< Content-Type: application/json\r\n",
      "< Content-Length: 8458\r\n",
      "< Connection: keep-alive\r\n",
      "< \r\n",
      "{ [8458 bytes data]\n",
      "\r",
      "100 13.5M  100  8458  100 13.5M     74   122k  0:01:54  0:01:53  0:00:01  2112\n",
      "* Connection #0 to host 127.0.0.1 left intact\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import base64\n",
    "def send_request(audio_path,url):\n",
    "    print('using',audio_path)\n",
    "    #=====================================================================\n",
    "    audio_base64 = base64.b64encode(open(audio_path, \"rb\").read())\n",
    "    ext = audio_path.split('.')[-1]\n",
    "    payload = audio_base64\n",
    "    request_dict ={\n",
    "        'data':payload.decode(),\n",
    "        'ext':ext}\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(mode='w+',suffix='.json',delete=True) as f:\n",
    "        json.dump(request_dict,f)    \n",
    "        f.seek(0)\n",
    "        \n",
    "        os.system(f'bash predict.sh {url} {f.name} \"application/json\"')\n",
    "\n",
    "# audio_path = '/home/ec2-user/SageMaker/Audio_James_Randi.wav'\n",
    "# audio_path = '/home/ec2-user/SageMaker/Audio_James_Randi_Long_Version.ogg'\n",
    "audio_path = '/home/ec2-user/SageMaker/thecantervilleghostversion2_01_wilde_128kb.mp3'\n",
    "send_request(audio_path,'127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d4c5ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'predictor'\n",
      "/home/ec2-user/SageMaker/whisper-async1/transcription\n"
     ]
    }
   ],
   "source": [
    "%cd predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5104b343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/whisper-async1/local_test\n"
     ]
    }
   ],
   "source": [
    "%cd local_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a26f790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict.sh  send_request.py  serve_local.sh\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e3e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
